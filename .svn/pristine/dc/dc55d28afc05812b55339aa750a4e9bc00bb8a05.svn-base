#ifndef MULTILAYERPERCEPTRON_H
#define MULTILAYERPERCEPTRON_H

#include <cstdarg>
#include <vector>

#include "../../PhysMath/src/physmath.h"

/**
 * 
 **/
template<int L>
class MultilayerPerceptron {
private:
	std::vector<Vectorf*> _activations;
	std::vector<Matrixf*> _weights;
	void activate(int, int);
public:
	void setWeights(std::vector<float>&);
public:
	MultilayerPerceptron(int, ...);
	~MultilayerPerceptron(void);
	Vectorf process(Vectorf&);
	void randomize(void);
	void printCompleteStatus(void);
};

/**
 * 
 **/
template<int L>
MultilayerPerceptron<L>::MultilayerPerceptron(int n, ...) {
	// Ensure we have at least two layers (input + output).
	if(L < 2)
		throw;
	// Process variable number of arguments.
	va_list va;
	va_start(va, n);
	_activations.push_back(new Vectorf(n));
	int d;
	for(int i = 1; i < L; ++i) {
		// Get next argument.
		d = va_arg(va, int);
		// Must have at least one node in a layer.
		if(d < 1)
			throw;
		// Load new activation vectors.
		_activations.push_back(new Vectorf(d));
		// Load new weight matrix.
		_weights.push_back(new Matrixf(n, d));
		n = d;
	}
	// Clean up variable argument list.
	va_end(va);
}

/**
 * 
 **/
template<int L>
MultilayerPerceptron<L>::~MultilayerPerceptron(void) {
	// Clean up activation vectors.
	std::vector<Vectorf*>::iterator ait;
	for(ait = _activations.begin(); ait != _activations.end(); ++ait)
		delete *ait;
	// Clean up weight matrices.
	std::vector<Matrixf*>::iterator wit;
	for(wit = _weights.begin(); wit != _weights.end(); ++wit)
		delete *wit;
}

/**
 * 
 **/
template<int L>
void MultilayerPerceptron<L>::activate(int layer, int node) {
	// Input layer cannot be activated.
	if(layer <= 0)
		throw;
	// Shortcuts.
	Matrixf* weights = _weights[layer - 1];
	Vectorf* prev = _activations[layer - 1];
	// Calculate raw weighted activation.
	float activation = 0;
	for(int i = 0; i < weights->getNumColumns(); ++i)
		activation += weights->get(i, node) * prev->get(i);
	// Apply activation function and store.
	_activations[layer]->set(tanh(activation), node);
}

/**
 * 
 **/
template<int L>
void MultilayerPerceptron<L>::setWeights(std::vector<float>& weights) {
	int rows, cols, count = -1;
	std::vector<Matrixf*>::iterator wit;
	for(wit = _weights.begin(); wit != _weights.end(); ++wit) {
		rows = (*wit)->getNumRows(), cols = (*wit)->getNumColumns();
		for(int r = 0; r < rows; ++r)
			for(int c = 0; c < cols; ++c)
				(*wit)->set(weights[++count], c, r);
	}
}

/**
 * 
 **/
template<int L>
Vectorf MultilayerPerceptron<L>::process(Vectorf& input) {
	// Clamp input activations.
	*_activations[0] = input;
	// Feed forward.
	int layers = _activations.size(), nodes;
	for(int layer = 1; layer < layers; ++layer) {
		nodes = _activations[layer]->getSize();
		for(int node = 0; node < nodes; ++node)
			activate(layer, node);
	}
	return *(_activations.back());
}

/**
 * 
 **/
template<int L>
void MultilayerPerceptron<L>::randomize(void) {
	int rows, cols;
	std::vector<Matrixf*>::iterator wit;
	for(wit = _weights.begin(); wit != _weights.end(); ++wit) {
		rows = (*wit)->getNumRows(), cols = (*wit)->getNumColumns();
		for(int r = 0; r < rows; ++r)
			for(int c = 0; c < cols; ++c)
				(*wit)->set(2 * (float(rand()) / RAND_MAX) - 1, c, r);
	}
}

/**
 * 
 **/
template<int L>
void MultilayerPerceptron<L>::printCompleteStatus(void) {
	cout << "ACTIVATIONS:" << endl;
	std::vector<Vectorf*>::iterator ait;
	for(ait = _activations.begin(); ait != _activations.end(); ++ait)
		cout << **ait << endl;
	cout << "WEIGHTS:" << endl;
	std::vector<Matrixf*>::iterator wit;
	for(wit = _weights.begin(); wit != _weights.end(); ++wit)
		cout << **wit << endl;
}

#endif